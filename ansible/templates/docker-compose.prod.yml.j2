x-restart-policy: &restart_policy
  restart: unless-stopped

x-logging: &logging
  logging:
    driver: 'json-file'
    options:
      max-size: '{{ logging.max_size }}'
      max-file: '{{ logging.max_files }}'

x-healthcheck: &healthcheck
  interval: 10s
  start_period: 5s
  timeout: 10s
  retries: 5

x-api-environments: &api_enviroments
  APP__NAME: ${APP__NAME:-null}
  APP__VERSION: ${APP__VERSION:-null}
  APP__TIMEZONE: ${APP__TIMEZONE:-null}
  POSTGRES__USER: ${POSTGRES__USER:-null}
  POSTGRES__PASSWORD: ${POSTGRES__PASSWORD:-null}
  POSTGRES__DB: ${POSTGRES__DB:-null}
  POSTGRES__HOST: ${POSTGRES__HOST:-null}
  POSTGRES__PORT: ${POSTGRES__PORT:-null}
  APP__CORS_ORIGINS: ${APP__CORS_ORIGINS:-null}
  SENTRY__DSN: ${SENTRY__DSN:-null}
  SENTRY__ENVIRONMENT: ${SENTRY__ENVIRONMENT:-null}

x-api-image: &api_image
  image: {{ container_registry }}/{{ github_repository }}/api:${APP__VERSION}
  build:
    context: api
    dockerfile: Dockerfile.prod

x-api-defaults: &api_defaults
  <<: [*api_image]
  environment:
    <<: [*api_enviroments]
  depends_on:
    pgbouncer:
      condition: service_healthy
      restart: true
    redis-cache:
      condition: service_healthy
      restart: true
    rabbitmq:
      condition: service_healthy
      restart: true
  networks:
    - traefik
    - api
    - api-public
  volumes:
    - /etc/timezone:/etc/timezone:ro
    - /etc/localtime:/etc/localtime:ro
    - /var/run/docker.sock:/var/run/docker.sock
    - ./api/app/configs:/app/app/configs

x-worker-defaults: &worker_defaults
  <<: [*api_image]
  networks:
    - api
    - api-public
  environment:
    <<: [*api_enviroments]
  depends_on:
    prestart:
      condition: service_completed_successfully
      restart: true
    pgbouncer:
      condition: service_healthy
      restart: true
    redis-cache:
      condition: service_healthy
      restart: true
    rabbitmq:
      condition: service_healthy
      restart: true
  volumes:
    - /etc/timezone:/etc/timezone:ro
    - /etc/localtime:/etc/localtime:ro
    - ./api/app/configs:/app/app/configs

services:
  autoheal:
    <<: [*restart_policy, *logging]
    image: willfarrell/autoheal:1.2.0
    profiles:
      - autoheal
    network_mode: none
    volumes:
      - /etc/timezone:/etc/timezone:ro
      - /etc/localtime:/etc/localtime:ro
      - /var/run/docker.sock:/var/run/docker.sock
    environment:
      AUTOHEAL_CONTAINER_LABEL: autoheal-${COMPOSE_PROJECT_NAME}
      AUTOHEAL_INTERVAL: 10
      AUTOHEAL_START_PERIOD: 300

  proxy:
    <<: [*restart_policy, *logging]
    image: traefik:v3.2
    hostname: ${COMPOSE_PROJECT_NAME}-proxy
    ports:
      - ${APP__PORT}:80
    expose:
      - 8080
    volumes:
      - /etc/timezone:/etc/timezone:ro
      - /etc/localtime:/etc/localtime:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
    networks:
      - traefik
      - traefik-public
      - caddy
    extra_hosts:
      - host.docker.internal:host-gateway
    environment:
      - COMPOSE_PROJECT_NAME=${COMPOSE_PROJECT_NAME}
    command:
      - --providers.docker=true
      - --providers.docker.constraints=Label(`traefik.constraint-label`, `${COMPOSE_PROJECT_NAME}`)
      - --providers.docker.exposedbydefault=false
      - --entrypoints.${COMPOSE_PROJECT_NAME}_http.address=:80
      - --accesslog
      - --log
      - --metrics.prometheus=true
      - --ping
    labels:
      - traefik.enable=true
      - traefik.constraint-label=${COMPOSE_PROJECT_NAME}
      - traefik.docker.network=${COMPOSE_PROJECT_NAME}_traefik
      - traefik.http.routers.${COMPOSE_PROJECT_NAME}_proxy.entrypoints=${COMPOSE_PROJECT_NAME}_http
      - traefik.http.services.${COMPOSE_PROJECT_NAME}_proxy.loadbalancer.server.port=80
      - autoheal-${COMPOSE_PROJECT_NAME}=true
    healthcheck:
      <<: *healthcheck
      test: ['CMD', 'traefik', 'healthcheck', '--ping']

  db:
    <<: [*restart_policy, *logging]
    image: postgres:15-alpine
    hostname: ${COMPOSE_PROJECT_NAME}-db
    command: >
      postgres
      -c shared_preload_libraries='pg_stat_statements'
      -c pg_stat_statements.track=all
    volumes:
      - /etc/timezone:/etc/timezone:ro
      - /etc/localtime:/etc/localtime:ro
      - app-db-data:/var/lib/postgresql/data/
      - ./postgres/init-multiple-dbs.sh:/docker-entrypoint-initdb.d/init-multiple-dbs.sh
    networks:
      - api
      - db
    environment:
      - PGDATA=/var/lib/postgresql/data/pgdata
      - POSTGRES_USER=${POSTGRES__USER}
      - POSTGRES_PASSWORD=${POSTGRES__PASSWORD}
      - POSTGRES_DB=${POSTGRES__DB}
      - POSTGRES_HOST_AUTH_METHOD=scram-sha-256
      - POSTGRES_INITDB_ARGS=--auth-host=scram-sha-256 --auth-local=scram-sha-256
    expose:
      - 5432
{% if resource_limits is defined %}
    deploy:
      resources:
        limits:
          memory: {{ resource_limits.db.memory }}
          cpus: '{{ resource_limits.db.cpu }}'
{% endif %}
    labels:
      - autoheal-${COMPOSE_PROJECT_NAME}=true
    healthcheck:
      <<: *healthcheck
      test:
        [
          'CMD-SHELL',
          "sh -c 'pg_isready -U $$POSTGRES_USER -d app && pg_isready -U $$POSTGRES_USER -d metabaseappdb'",
        ]

  pgbouncer:
    <<: [*restart_policy, *logging]
    image: edoburu/pgbouncer:v1.23.1-p2
    networks:
      - api
      - db
    volumes:
      - /etc/timezone:/etc/timezone:ro
      - /etc/localtime:/etc/localtime:ro
      - ./pgbouncer/pgbouncer.ini:/etc/pgbouncer/pgbouncer.ini:ro
    environment:
      - DB_HOST=db
      - DB_USER=${POSTGRES__USER}
      - DB_PASSWORD=${POSTGRES__PASSWORD}
      - DB_NAME=${POSTGRES__DB}
      - POOL_MODE=transaction
      - MAX_CLIENT_CONN=1000
      - AUTH_TYPE=scram-sha-256
      - AUTH_USER=${POSTGRES__USER}
      - ADMIN_USERS=postgres,${POSTGRES__USER}
    expose:
      - 5432
    depends_on:
      db:
        condition: service_healthy
        restart: true
    healthcheck:
      <<: *healthcheck
      test: ['CMD', 'pg_isready', '-h', 'localhost']

  pgadmin:
    <<: [*restart_policy, *logging]
    profiles:
      - pgadmin
    image: dpage/pgadmin4:7
    hostname: ${COMPOSE_PROJECT_NAME}-pgadmin
    user: root
    entrypoint: >
      /bin/sh -c "
      chmod 600 /pgpass;
      /entrypoint.sh;
      "
    networks:
      - traefik
      - api
    depends_on:
      db:
        condition: service_healthy
        restart: true
    expose:
      - 5050
    environment:
      - PGADMIN_LISTEN_PORT=5050
      - PGADMIN_DEFAULT_EMAIL=${PGADMIN__EMAIL}
      - PGADMIN_DEFAULT_PASSWORD=${PGADMIN__PASSWORD}
      - SCRIPT_NAME=/pgadmin
      - PGADMIN_CONFIG_SERVER_MODE=False
      - PGADMIN_CONFIG_MASTER_PASSWORD_REQUIRED=False
    volumes:
      - /etc/timezone:/etc/timezone:ro
      - /etc/localtime:/etc/localtime:ro
      - app-pgadmin-data:/var/lib/pgadmin
      - ./pgadmin/servers.json:/pgadmin4/servers.json
      - ./pgadmin/pgpass:/pgpass
    labels:
      - traefik.enable=true
      - traefik.constraint-label=${COMPOSE_PROJECT_NAME}
      - traefik.docker.network=${COMPOSE_PROJECT_NAME}_traefik
      - traefik.http.routers.${COMPOSE_PROJECT_NAME}_pgadmin.rule=PathPrefix(`/pgadmin`)
      - traefik.http.routers.${COMPOSE_PROJECT_NAME}_pgadmin.entrypoints=${COMPOSE_PROJECT_NAME}_http
      - traefik.http.services.${COMPOSE_PROJECT_NAME}_pgadmin.loadbalancer.server.port=5050

  rabbitmq:
    <<: [*restart_policy, *logging]
    image: rabbitmq:3.9.8-management-alpine
    hostname: ${COMPOSE_PROJECT_NAME}-rabbitmq
    environment:
      - RABBITMQ_DEFAULT_USER=${RABBITMQ__USER}
      - RABBITMQ_DEFAULT_PASS=${RABBITMQ__PASS}
      - RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS=-rabbitmq_management path_prefix "/rabbitmq"
    networks:
      - traefik
      - api
    expose:
      - 5672
      - 15672
      - 15692
    volumes:
      - /etc/timezone:/etc/timezone:ro
      - /etc/localtime:/etc/localtime:ro
      - app-rabbitmq-data:/var/lib/rabbitmq/mnesia
{% if resource_limits is defined %}
    deploy:
      resources:
        limits:
          memory: {{ resource_limits.rabbitmq.memory | default('512m') }}
          cpus: '{{ resource_limits.rabbitmq.cpu | default('0.5') }}'
{% endif %}
    labels:
      - traefik.enable=true
      - traefik.constraint-label=${COMPOSE_PROJECT_NAME}
      - traefik.docker.network=${COMPOSE_PROJECT_NAME}_traefik
      - traefik.http.routers.${COMPOSE_PROJECT_NAME}_rabbitmq.rule=PathPrefix(`/rabbitmq/`)
      - traefik.http.routers.${COMPOSE_PROJECT_NAME}_rabbitmq.entrypoints=${COMPOSE_PROJECT_NAME}_http
      - traefik.http.services.${COMPOSE_PROJECT_NAME}_rabbitmq.loadbalancer.server.port=15672
      - autoheal-${COMPOSE_PROJECT_NAME}=true
    healthcheck:
      <<: *healthcheck
      test: ['CMD-SHELL', 'rabbitmq-diagnostics -q ping']

  redis-cache:
    <<: [*restart_policy, *logging]
    image: docker.dragonflydb.io/dragonflydb/dragonfly:v1.18.1
    hostname: ${COMPOSE_PROJECT_NAME}-redis-cache
    ulimits:
      memlock: -1
    networks:
      - api
    expose:
      - 6379
    volumes:
      - /etc/timezone:/etc/timezone:ro
      - /etc/localtime:/etc/localtime:ro
    command:
      - '--maxmemory=5G'
      - '--cache_mode=true'
      - '--dbfilename='
{% if resource_limits is defined %}
    deploy:
      resources:
        limits:
          memory: {{ resource_limits.redis.memory }}
          cpus: '{{ resource_limits.redis.cpu }}'
{% endif %}
    labels:
      - autoheal-${COMPOSE_PROJECT_NAME}=true
    healthcheck:
      <<: *healthcheck
      test: ['CMD-SHELL', '/usr/local/bin/healthcheck.sh']

  prestart:
    <<: [*logging, *api_defaults]
    hostname: ${COMPOSE_PROJECT_NAME}-prestart
    container_name: ${COMPOSE_PROJECT_NAME}_prestart
    command: bash /prestart.sh
    labels:
      - autoheal-${COMPOSE_PROJECT_NAME}=true
    restart: 'no'

  api:
    <<: [*restart_policy, *logging, *api_defaults]
    hostname: ${COMPOSE_PROJECT_NAME}-api
    container_name: ${COMPOSE_PROJECT_NAME}_api
    command:
      - fastapi
      - run
      - --port=80
      - 'app/main.py'
      - --proxy-headers
      - --workers=${API__CONCURRENCY}
    expose:
      - 80
    extra_hosts:
      - host.docker.internal:host-gateway
{% if resource_limits is defined %}
    deploy:
      resources:
        limits:
          memory: {{ resource_limits.api.memory }}
          cpus: '{{ resource_limits.api.cpu }}'
{% endif %}
    labels:
      - traefik.enable=true
      - traefik.constraint-label=${COMPOSE_PROJECT_NAME}
      - traefik.docker.network=${COMPOSE_PROJECT_NAME}_traefik
      - traefik.http.routers.${COMPOSE_PROJECT_NAME}_api.rule=PathPrefix(`/api`) || PathPrefix(`/static`) || PathPrefix(`/docs`) || PathPrefix(`/redoc`) || PathPrefix(`/openapi.json`)
      - traefik.http.routers.${COMPOSE_PROJECT_NAME}_api.entrypoints=${COMPOSE_PROJECT_NAME}_http
      - traefik.http.services.${COMPOSE_PROJECT_NAME}_api.loadbalancer.server.port=80
      - traefik.http.middlewares.${COMPOSE_PROJECT_NAME}_api-ratelimit.ratelimit.average=100
      - traefik.http.middlewares.${COMPOSE_PROJECT_NAME}_api-ratelimit.ratelimit.burst=200
      - traefik.http.middlewares.${COMPOSE_PROJECT_NAME}_api-ratelimit.ratelimit.period=1m
      - autoheal-${COMPOSE_PROJECT_NAME}=true
    depends_on:
      prestart:
        condition: service_completed_successfully
        restart: true
      pgbouncer:
        condition: service_healthy
        restart: true
      redis-cache:
        condition: service_healthy
        restart: true
      rabbitmq:
        condition: service_healthy
        restart: true
    networks:
      - traefik
      - api
      - api-public
    healthcheck:
      <<: *healthcheck
      test: ['CMD', 'curl', '-f', 'http://localhost:80/health']
      start_period: 20s

  worker:
    <<: [*restart_policy, *logging, *worker_defaults]
    hostname: ${COMPOSE_PROJECT_NAME}-worker
    container_name: ${COMPOSE_PROJECT_NAME}_worker
    command:
      - taskiq
      - worker
      - app.worker:broker
      - app.src.tasks
    extra_hosts:
      - host.docker.internal:host-gateway
    labels:
      - autoheal-${COMPOSE_PROJECT_NAME}=true

  worker-beat:
    <<: [*restart_policy, *logging, *worker_defaults]
    hostname: ${COMPOSE_PROJECT_NAME}-worker-beat
    container_name: ${COMPOSE_PROJECT_NAME}_worker_beat
    command:
      - taskiq
      - scheduler
      - app.worker:scheduler
      - app.src.tasks

  web:
    <<: [*restart_policy, *logging]
    hostname: ${COMPOSE_PROJECT_NAME}-web
    container_name: ${COMPOSE_PROJECT_NAME}_web
    image: {{ container_registry }}/{{ github_repository }}/web:${APP__VERSION}
    build:
      context: frontend
      dockerfile: Dockerfile
      target: production
    command: ['nginx', '-g', 'daemon off;']
    networks:
      - traefik
    ports:
      - 18080:80
    expose:
      - 80
{% if resource_limits is defined %}
    deploy:
      resources:
        limits:
          memory: {{ resource_limits.web.memory }}
          cpus: '{{ resource_limits.web.cpu }}'
{% endif %}
    labels:
      - traefik.enable=true
      - traefik.constraint-label=${COMPOSE_PROJECT_NAME}
      - traefik.docker.network=${COMPOSE_PROJECT_NAME}_traefik
      - traefik.http.routers.${COMPOSE_PROJECT_NAME}_web.rule=PathPrefix(`/`)
      - traefik.http.routers.${COMPOSE_PROJECT_NAME}_web.entrypoints=${COMPOSE_PROJECT_NAME}_http
      - traefik.http.services.${COMPOSE_PROJECT_NAME}_web.loadbalancer.server.port=80

networks:
  traefik-public:
  api-public:
  traefik:
  api:
  db:
  caddy:
    external: true
    name: caddy_net

volumes:
  app-db-data:
  app-pgadmin-data:
  app-redisinsight-data:
  app-rabbitmq-data:
